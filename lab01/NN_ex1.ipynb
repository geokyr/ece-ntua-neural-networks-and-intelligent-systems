{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEAM 44 - HCC Survival (U05) - kdd cyberattack (K09)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: UCI dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pip --upgrade\n",
    "%pip install scikit-learn --upgrade\n",
    "%pip install numpy --upgrade\n",
    "%pip install matplotlib --upgrade\n",
    "%pip install imbalanced-learn --upgrade\n",
    "%pip install pandas --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intoduction and Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part we will use a UCI dataset, [HCC Survival](https://archive.ics.uci.edu/ml/datasets/HCC+Survival).\n",
    "\n",
    "HCC dataset was obtained at a University Hospital in Portugal and contais several demographic, risk factors, laboratory and overall survival features of 165 real patients diagnosed with HCC. The dataset contains 49 features selected according to the EASL-EORTC (European Association for the Study of the Liver - European Organisation for Research and Treatment of Cancer) Clinical Practice Guidelines, which are the current state-of-the-art on the management of HCC.\n",
    "\n",
    "This is an heterogeneous dataset, with 23 quantitative variables, and 26 qualitative variables. Overall, missing data represents 10.22% of the whole dataset and only eight patients have complete information in all fields (4.85%). The target variables is the survival at 1 year, and was encoded as a binary variable: 0 (dies) and 1 (lives). A certain degree of class-imbalance is also present (63 cases labeled as dies and 102 as lives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read data from hcc_data.txt file and replace missing values with NaN\n",
    "df = pd.read_csv(\"resources/hcc-data.txt\", header=None, na_values = \"?\")\n",
    "\n",
    "# print basic info about dataframe\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only transformation applied to the original dataset was the replacement of missing values (denoted by \"?\") by NaN value, using the pandas.read_csv function with the na_values parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 165 instances and 49 features in the dataset. The type of the features are as follows.\n",
    "\n",
    "* Gender: nominal\n",
    "* Symptoms: nominal\n",
    "* Alcohol: nominal\n",
    "* Hepatitis B Surface Antigen: nominal\n",
    "* Hepatitis B e Antigen: nominal\n",
    "* Hepatitis B Core Antibody: nominal\n",
    "* Hepatitis C Virus Antibody: nominal\n",
    "* Cirrhosis : nominal\n",
    "* Endemic Countries: nominal\n",
    "* Smoking: nominal\n",
    "* Diabetes: nominal\n",
    "* Obesity: nominal\n",
    "* Hemochromatosis: nominal\n",
    "* Arterial Hypertension: nominal\n",
    "* Chronic Renal Insufficiency: nominal\n",
    "* Human Immunodeficiency Virus: nominal\n",
    "* Nonalcoholic Steatohepatitis: nominal\n",
    "* Esophageal Varices: nominal\n",
    "* Splenomegaly: nominal\n",
    "* Portal Hypertension: nominal\n",
    "* Portal Vein Thrombosis: nominal\n",
    "* Liver Metastasis: nominal\n",
    "* Radiological Hallmark: nominal\n",
    "* Age at diagnosis: integer\n",
    "* Grams of Alcohol per day: continuous\n",
    "* Packs of cigarets per year: continuous\n",
    "* Performance Status: ordinal\n",
    "* Encefalopathy degree: ordinal\n",
    "* Ascites degree: ordinal\n",
    "* International Normalised Ratio: continuous\n",
    "* Alpha-Fetoprotein (ng/mL): continuous\n",
    "* Haemoglobin (g/dL): continuous\n",
    "* Mean Corpuscular Volume (fl): continuous\n",
    "* Leukocytes(G/L): continuous\n",
    "* Platelets (G/L): continuous\n",
    "* Albumin (mg/dL): continuous\n",
    "* Total Bilirubin(mg/dL): continuous\n",
    "* Alanine transaminase (U/L): continuous\n",
    "* Aspartate transaminase (U/L): continuous\n",
    "* Gamma glutamyl transferase (U/L): continuous\n",
    "* Alkaline phosphatase (U/L): continuous\n",
    "* Total Proteins (g/dL): continuous\n",
    "* Creatinine (mg/dL): continuous\n",
    "* Number of Nodules: integer\n",
    "* Major dimension of nodule (cm): continuous\n",
    "* Direct Bilirubin (mg/dL): continuous\n",
    "* Iron (mcg/dL): continuous\n",
    "* Oxygen Saturation (%): continuous\n",
    "* Ferritin (ng/mL): continuous\n",
    "\n",
    "All the nominal features (the first 23) are not ordinal features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no labels for the features, and no row indexing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last column (50th) is the label of the classes, which is the survival at 1 year, and was encoded as a binary variable: 0 (dies) and 1 (lives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances with missing values: 157\n",
      "Percentage of instances with missing values: 95.15%\n",
      "Percentage of missing values to total number of values: 10.22%\n",
      "Class frequencies: [ 63 102]\n",
      "Percentage of negative instances: 38.18%\n",
      "Percentage of positive instances: 61.82%\n",
      "Class frequency ratio: 1.62\n"
     ]
    }
   ],
   "source": [
    "# slice the dataframe to split the features from the labels\n",
    "labels_df = df.iloc[:, [49]]\n",
    "labels = labels_df.values.reshape(165)\n",
    "features_df = df.iloc[:, 0:49]\n",
    "features = features_df.values\n",
    "\n",
    "print(\"Number of instances with missing values:\", features_df.isnull().values.any(axis=1).sum())\n",
    "print(f'Percentage of instances with missing values: {np.format_float_positional(features_df.isnull().values.any(axis=1).sum()/features_df.shape[0]*100, 2)}%')\n",
    "print(f'Percentage of missing values to total number of values: {np.format_float_positional(features_df.isnull().values.sum()/features_df.size*100, 2)}%')\n",
    "\n",
    "print(\"Class frequencies:\", np.bincount(labels))\n",
    "print(f'Percentage of negative instances: {np.format_float_positional(np.bincount(labels)[0]/labels.shape[0]*100, 2)}%')\n",
    "print(f'Percentage of positive instances: {np.format_float_positional(np.bincount(labels)[1]/labels.shape[0]*100, 2)}%')\n",
    "print(\"Class frequency ratio:\", np.format_float_positional(np.max(np.bincount(labels))/np.min(np.bincount(labels)), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are missing values. The number of instances with missing values is 157, and their percentage with respect to total number of instances is 95.15%. The missing data represents 10.22% of the whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 63 cases labeled as dies and 102 as lives, with 38.18% and 61.82% respectively. This is a class-imbalanced binary dataset, as the 60%-40% ratio is not respected, as showcased by the class frequency ratio with a value over 1.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp1 = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imp2 = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "mask1 = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 43]\n",
    "mask2 = [24, 25, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48]\n",
    "imp1.fit(X_train[:, mask1])\n",
    "imp2.fit(X_train[:, mask2])\n",
    "\n",
    "X_train[:, mask1] = imp1.transform(X_train[:, mask1])\n",
    "X_train[:, mask2] = imp2.transform(X_train[:, mask2])\n",
    "X_test[:, mask1] = imp1.transform(X_test[:, mask1])\n",
    "X_test[:, mask2] = imp2.transform(X_test[:, mask2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the missing values we will use the SimpleImputer class from the sklearn.impute module. We will use the most frequent and the mean strategy. The most frequent strategy replaces missing values using the most frequent value along each column, while the mean strategy replaces missing values using the mean value along each column.\n",
    "\n",
    "We used the most frequent strategy on the nominal, integer and ordinal features, where mean value would not be acceptable, and the mean strategy on the continuous features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(X_train)\n",
    "test_data = pd.DataFrame(X_test)\n",
    "\n",
    "# concat the train and test data and create dummy features for the nominal ones\n",
    "data = pd.concat([train_data, test_data], axis=0)\n",
    "data = pd.get_dummies(data, columns = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22])\n",
    "\n",
    "# split the data to train and test again with 70-30 ratio\n",
    "X_train = data.iloc[0:115, :].values\n",
    "X_test = data.iloc[115:165, :].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the nominal features we will use the get_dummies function from the pandas module. This function is used to convert categorical variable into dummy/indicator variables.\n",
    "\n",
    "We had to concat the train and test data so that the dummy/indicator variables end up being the same for both sets. We then split the data back into train and test sets, following the initial 70-30 ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import NaiveBayesClassifier\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# gnb = GaussianNB()\n",
    "# gnb.fit(X_train, y_train)\n",
    "# y_pred = gnb.predict(X_test)\n",
    "# print(y_test)\n",
    "# # import metrics\n",
    "# from sklearn import metrics\n",
    "# print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# φέρνουμε τις γνωστές μας κλάσεις για preprocessing\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler # φέρνουμε τον StandarScaler ως transformer που έχει .transform kai ΄όχι ως scale()\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# αρχικοποιούμε τον εκτιμητή (ταξινομητής) και τους μετασχηματιστές χωρίς υπερ-παραμέτρους\n",
    "selector = VarianceThreshold()\n",
    "scaler = StandardScaler()\n",
    "ros = RandomOverSampler()\n",
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Kaggle dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle dataset is [kdd cyberattack](https://www.kaggle.com/datasets/slashtea/kdd-cyberattack)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
